{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b72ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e496f45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857789f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomNN(\n",
      "  (layer): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RandomNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(in_features=1, out_features=1)\n",
    "        #self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
    "        #self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "        # Can also put sigmoid in the model \n",
    "        # This would mean you don't need to use it on the predictions\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "      # Intersperse the ReLU activation function between layers\n",
    "       #return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "       return self.layer(x)\n",
    "\n",
    "NN_model = RandomNN().to(device)\n",
    "print(NN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3fe6db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[2.]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9712], device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.layer.weight, NN_model.layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0feb97ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[2.]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7a03046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.0], [1.0]]).to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75e84b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9712],\n",
      "        [0.6088]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "res = NN_model(x)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aae7e722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.layer.weight[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "783192ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    NN_model.layer.weight[0,0] = 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93bbce6",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/66724071/manually-assign-weights-using-pytorch\n",
    "https://www.reddit.com/r/pytorch/comments/m9azt9/manually_assign_weights_using_pytorch/\n",
    "these links might help!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26785a94",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5576d4e0944c7c8d3e746c7156f0cd5a57b8627925746e47be452fe66d712228"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
