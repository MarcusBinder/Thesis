{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b72ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "from stable_baselines3 import PPO, A2C, SAC, TD3, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "\n",
    "from sb3_contrib import QRDQN, TQC\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1c915",
   "metadata": {},
   "source": [
    "Alternativt:\n",
    "https://github.com/optuna/optuna-examples/blob/main/rl/sb3_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e14608",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 100  # Maximum number of trials\n",
    "N_JOBS = 8 # Number of jobs to run in parallel\n",
    "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
    "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
    "N_TIMESTEPS = int(2e4)  # Training budget\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_ENVS = 5\n",
    "N_EVAL_EPISODES = 10\n",
    "TIMEOUT = None                   # int(60 * 15)  # 15 minutes\n",
    "\n",
    "ENV_ID = \"CartPole-v1\"\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": ENV_ID,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6d743",
   "metadata": {},
   "source": [
    "Search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4027a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Sampler for A2C hyperparameters.\n",
    "\n",
    "    :param trial: Optuna trial object\n",
    "    :return: The sampled hyperparameters for the given trial.\n",
    "    \"\"\"\n",
    "    # Discount factor between 0.9 and 0.9999\n",
    "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
    "    # 8, 16, 32, ... 1024\n",
    "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    # TODO:\n",
    "    # - define the learning rate search space [1e-5, 1] (log) -> `suggest_float`\n",
    "    # - define the network architecture search space [\"tiny\", \"small\"] -> `suggest_categorical`\n",
    "    # - define the activation function search space [\"tanh\", \"relu\"]\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\"])\n",
    "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "\n",
    "    # Display true values\n",
    "    trial.set_user_attr(\"gamma_\", gamma)\n",
    "    trial.set_user_attr(\"n_steps\", n_steps)\n",
    "\n",
    "    net_arch = [\n",
    "        {\"pi\": [64], \"vf\": [64]}\n",
    "        if net_arch == \"tiny\"\n",
    "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
    "    ]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
    "\n",
    "    return {\n",
    "        \"n_steps\": n_steps,\n",
    "        \"gamma\": gamma,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"max_grad_norm\": max_grad_norm,\n",
    "        \"policy_kwargs\": {\n",
    "            \"net_arch\": net_arch,\n",
    "            \"activation_fn\": activation_fn,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3294c3b2",
   "metadata": {},
   "source": [
    "Define objective function\n",
    "\n",
    "First we define a custom callback to report the results of periodic evaluations to Optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a3538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"\n",
    "    Callback used for evaluating and reporting a trial.\n",
    "    \n",
    "    :param eval_env: Evaluation environement\n",
    "    :param trial: Optuna trial object\n",
    "    :param n_eval_episodes: Number of evaluation episodes\n",
    "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
    "    :param deterministic: Whether the evaluation should\n",
    "        use a stochastic or deterministic policy.\n",
    "    :param verbose:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gym.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            # Evaluate policy (done in the parent class)\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            # Send report to Optuna\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2645e87",
   "metadata": {},
   "source": [
    "Then we define the objective function that is in charge of sampling hyperparameters, creating the model and then returning the result to Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe31ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function using by Optuna to evaluate\n",
    "    one configuration (i.e., one set of hyperparameters).\n",
    "\n",
    "    Given a trial object, it will sample hyperparameters,\n",
    "    evaluate it and report the result (mean episodic reward after training)\n",
    "\n",
    "    :param trial: Optuna trial object\n",
    "    :return: Mean episodic reward after training\n",
    "    \"\"\"\n",
    "\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    ### YOUR CODE HERE\n",
    "    # TODO: \n",
    "    # 1. Sample hyperparameters and update the default keyword arguments: `kwargs.update(other_params)`\n",
    "    # 2. Create the evaluation envs\n",
    "    # 3. Create the `TrialEvalCallback`\n",
    "\n",
    "    # 1. Sample hyperparameters and update the keyword arguments\n",
    "    kwargs.update(sample_a2c_params(trial))\n",
    "\n",
    "    # Create the RL model\n",
    "    model = A2C(**kwargs)\n",
    "\n",
    "    # 2. Create envs used for evaluation using `make_vec_env`, `ENV_ID` and `N_EVAL_ENVS`\n",
    "    eval_envs = make_vec_env(ENV_ID, N_EVAL_ENVS)\n",
    "\n",
    "    # 3. Create the `TrialEvalCallback` callback defined above that will periodically evaluate\n",
    "    # and report the performance using `N_EVAL_EPISODES` every `EVAL_FREQ`\n",
    "    # TrialEvalCallback signature:\n",
    "    # TrialEvalCallback(eval_env, trial, n_eval_episodes, eval_freq, deterministic, verbose)\n",
    "    eval_callback = TrialEvalCallback(eval_envs, \n",
    "                                      trial, \n",
    "                                      N_EVAL_EPISODES, \n",
    "                                      EVAL_FREQ, \n",
    "                                      deterministic = True)\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        # Train the model\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory\n",
    "        model.env.close()\n",
    "        eval_envs.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79bb51d",
   "metadata": {},
   "source": [
    "The optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c3eb6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-13 15:24:59,892]\u001b[0m A new study created in memory with name: no-name-f28176cb-52ea-44b3-b175-c5245990e73d\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:27:48,905]\u001b[0m Trial 6 finished with value: 152.9 and parameters: {'gamma': 0.018887104148856637, 'max_grad_norm': 2.0761441405335055, 'exponent_n_steps': 9, 'lr': 0.0003864224994658443, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 6 with value: 152.9.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:27:53,726]\u001b[0m Trial 1 finished with value: 94.6 and parameters: {'gamma': 0.008657936432580397, 'max_grad_norm': 1.8166526744365383, 'exponent_n_steps': 6, 'lr': 1.4661993286054031e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 6 with value: 152.9.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:27:57,751]\u001b[0m Trial 4 finished with value: 132.7 and parameters: {'gamma': 0.06678567613717995, 'max_grad_norm': 1.348715916053181, 'exponent_n_steps': 9, 'lr': 4.711903420866859e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 6 with value: 152.9.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:28:04,621]\u001b[0m Trial 0 finished with value: 9.6 and parameters: {'gamma': 0.0390841760956516, 'max_grad_norm': 0.32251963733099437, 'exponent_n_steps': 5, 'lr': 0.30928234391327114, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 152.9.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:28:21,248]\u001b[0m Trial 5 finished with value: 358.9 and parameters: {'gamma': 0.062352592726648705, 'max_grad_norm': 0.579782846322138, 'exponent_n_steps': 4, 'lr': 0.010545977700123615, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 5 with value: 358.9.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:28:37,641]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:28:40,677]\u001b[0m Trial 3 finished with value: 30.7 and parameters: {'gamma': 0.013778999627030036, 'max_grad_norm': 0.7876937267194687, 'exponent_n_steps': 4, 'lr': 0.0028079347426250047, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 5 with value: 358.9.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:29:06,409]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:29:12,136]\u001b[0m Trial 2 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:29:16,815]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:29:34,792]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:29:45,076]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:29:58,030]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:30:19,756]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:30:26,750]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:30:59,070]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:31:45,345]\u001b[0m Trial 16 finished with value: 479.8 and parameters: {'gamma': 0.0004081132094110344, 'max_grad_norm': 4.284411620652414, 'exponent_n_steps': 8, 'lr': 0.01530218149634166, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 16 with value: 479.8.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:31:50,657]\u001b[0m Trial 17 finished with value: 344.6 and parameters: {'gamma': 0.00012030145343965565, 'max_grad_norm': 4.120791246070422, 'exponent_n_steps': 7, 'lr': 0.014601593275959586, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 16 with value: 479.8.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:32:14,728]\u001b[0m Trial 18 finished with value: 433.3 and parameters: {'gamma': 0.0001218909003754543, 'max_grad_norm': 4.118678687521573, 'exponent_n_steps': 10, 'lr': 0.00884996689376952, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 16 with value: 479.8.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:32:15,986]\u001b[0m Trial 19 finished with value: 401.3 and parameters: {'gamma': 0.00016445775648222453, 'max_grad_norm': 3.8882088967444868, 'exponent_n_steps': 10, 'lr': 0.023135947622767838, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 16 with value: 479.8.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:32:53,078]\u001b[0m Trial 20 finished with value: 474.2 and parameters: {'gamma': 0.01350162681835485, 'max_grad_norm': 3.378577549924061, 'exponent_n_steps': 10, 'lr': 0.009963948886994067, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 16 with value: 479.8.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:33:00,717]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:33:19,200]\u001b[0m Trial 22 finished with value: 294.2 and parameters: {'gamma': 0.014982217008277367, 'max_grad_norm': 3.5281800194047803, 'exponent_n_steps': 10, 'lr': 0.005646822443001813, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 16 with value: 479.8.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:33:25,934]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:33:27,790]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:33:28,850]\u001b[0m Trial 21 finished with value: 500.0 and parameters: {'gamma': 0.015541241379918736, 'max_grad_norm': 3.3233335107808797, 'exponent_n_steps': 10, 'lr': 0.00991027945235939, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:33:52,237]\u001b[0m Trial 23 finished with value: 452.2 and parameters: {'gamma': 0.015143281026327598, 'max_grad_norm': 3.234320041790272, 'exponent_n_steps': 10, 'lr': 0.004244196477953088, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:34:14,023]\u001b[0m Trial 24 finished with value: 471.9 and parameters: {'gamma': 0.00011127692455170395, 'max_grad_norm': 4.700755043347918, 'exponent_n_steps': 10, 'lr': 0.007936806296861757, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:34:15,344]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:34:52,785]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:35:15,500]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:35:39,947]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:35:50,018]\u001b[0m Trial 29 finished with value: 500.0 and parameters: {'gamma': 0.003608684256008079, 'max_grad_norm': 3.024526382627912, 'exponent_n_steps': 9, 'lr': 0.003984965414584445, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:36:09,178]\u001b[0m Trial 30 finished with value: 126.5 and parameters: {'gamma': 0.0026790918396583326, 'max_grad_norm': 2.778675273004287, 'exponent_n_steps': 9, 'lr': 0.0020129630047685267, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:36:16,867]\u001b[0m Trial 31 finished with value: 500.0 and parameters: {'gamma': 0.004238758771864884, 'max_grad_norm': 2.6306746989770855, 'exponent_n_steps': 9, 'lr': 0.0013203866784314284, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:36:21,154]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:36:36,873]\u001b[0m Trial 33 finished with value: 500.0 and parameters: {'gamma': 0.0049104181825912275, 'max_grad_norm': 2.610407142566, 'exponent_n_steps': 9, 'lr': 0.002990320982592562, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:36:39,047]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:37:05,722]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:37:08,028]\u001b[0m Trial 35 finished with value: 471.1 and parameters: {'gamma': 0.003879843704798086, 'max_grad_norm': 2.6833447993758375, 'exponent_n_steps': 9, 'lr': 0.0016591673182280821, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:37:14,018]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:37:33,503]\u001b[0m Trial 41 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:37:40,079]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:37:48,710]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:38:07,517]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:38:08,201]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:39:07,961]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:39:31,821]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:39:39,043]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:40:06,647]\u001b[0m Trial 47 finished with value: 496.3 and parameters: {'gamma': 0.008708937009622882, 'max_grad_norm': 1.5148255879949282, 'exponent_n_steps': 7, 'lr': 0.0007413899482616393, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:40:08,509]\u001b[0m Trial 46 finished with value: 449.0 and parameters: {'gamma': 0.007713977130957727, 'max_grad_norm': 1.7082031709673116, 'exponent_n_steps': 7, 'lr': 0.0006701085476549198, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:40:09,402]\u001b[0m Trial 48 finished with value: 190.8 and parameters: {'gamma': 0.008830881664828, 'max_grad_norm': 1.6267676779276548, 'exponent_n_steps': 7, 'lr': 0.0007095027473540753, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:40:30,240]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:40:32,132]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:40:55,328]\u001b[0m Trial 51 finished with value: 491.9 and parameters: {'gamma': 0.00814981739559661, 'max_grad_norm': 1.179515679530061, 'exponent_n_steps': 7, 'lr': 0.000690552064713608, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:40:55,383]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:41:20,046]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:41:34,411]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:41:34,449]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:41:36,083]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:41:52,699]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:41:57,472]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:42:26,172]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:42:30,666]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:42:51,762]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:43:09,788]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:43:16,227]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:43:45,971]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:44:10,456]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:44:30,061]\u001b[0m Trial 74 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:44:35,229]\u001b[0m Trial 68 finished with value: 500.0 and parameters: {'gamma': 0.011674490073116963, 'max_grad_norm': 0.802132206510987, 'exponent_n_steps': 5, 'lr': 0.006817610689017697, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:44:41,622]\u001b[0m Trial 66 finished with value: 500.0 and parameters: {'gamma': 0.011702473491135429, 'max_grad_norm': 0.9671633201456813, 'exponent_n_steps': 5, 'lr': 0.0027590676065870415, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:44:41,642]\u001b[0m Trial 65 finished with value: 492.0 and parameters: {'gamma': 0.00379515395036158, 'max_grad_norm': 0.9840221831391651, 'exponent_n_steps': 5, 'lr': 0.0003133673003239428, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:44:57,234]\u001b[0m Trial 70 finished with value: 500.0 and parameters: {'gamma': 0.011722467277274622, 'max_grad_norm': 0.7868202539754054, 'exponent_n_steps': 8, 'lr': 0.0050870802172285215, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:45:02,724]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:45:28,725]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:45:42,609]\u001b[0m Trial 73 finished with value: 351.2 and parameters: {'gamma': 0.005651747210794734, 'max_grad_norm': 2.1803380980631615, 'exponent_n_steps': 8, 'lr': 0.005641113897659765, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:45:44,676]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:45:51,296]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:46:23,678]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:46:37,036]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:47:05,372]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:47:15,949]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:47:21,856]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:48:07,307]\u001b[0m Trial 81 finished with value: 500.0 and parameters: {'gamma': 0.018140277981642507, 'max_grad_norm': 0.5202288878567063, 'exponent_n_steps': 4, 'lr': 0.0035525161450782276, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:48:15,279]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:48:32,737]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:48:50,258]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:49:00,287]\u001b[0m Trial 84 finished with value: 500.0 and parameters: {'gamma': 0.018879392464492852, 'max_grad_norm': 0.518148294482426, 'exponent_n_steps': 4, 'lr': 0.01058128132874997, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:49:30,920]\u001b[0m Trial 87 finished with value: 291.7 and parameters: {'gamma': 0.023194507030428645, 'max_grad_norm': 0.44393912314646017, 'exponent_n_steps': 4, 'lr': 0.009866042123645393, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 21 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:49:53,214]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:49:58,090]\u001b[0m Trial 92 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-13 15:50:06,739]\u001b[0m Trial 93 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Set pytorch num threads to 1 for faster training\n",
    "\n",
    "#torch.set_num_threads(1)\n",
    "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "# Do not prune before 1/3 of the max budget is used\n",
    "pruner = MedianPruner(\n",
    "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
    ")\n",
    "# Create the study and start the hyperparameter optimization\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "\n",
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value}\")\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Write report\n",
    "study.trials_dataframe().to_csv(\"study_results_a2c_cartpole.csv\")\n",
    "\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig2 = plot_param_importances(study)\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7b19c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5576d4e0944c7c8d3e746c7156f0cd5a57b8627925746e47be452fe66d712228"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
